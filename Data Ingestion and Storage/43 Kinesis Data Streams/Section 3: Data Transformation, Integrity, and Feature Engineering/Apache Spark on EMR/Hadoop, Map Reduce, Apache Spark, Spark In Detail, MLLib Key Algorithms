üí° 1. What is Hadoop?
üß± Hadoop = Big Data Framework with 4 Core Components:

| Component         | What It Does                                                                    |
| ----------------- | ------------------------------------------------------------------------------- |
| **HDFS**          | Distributed file system (splits files across cluster with redundancy)           |
| **YARN**          | Manages resources in the cluster (stands for *Yet Another Resource Negotiator*) |
| **MapReduce**     | Framework for processing data in parallel using `Map()` and `Reduce()` steps    |
| **Hadoop Common** | Shared utilities & libraries (the foundation layer)                             |

üöÄ 2. MapReduce
Map: Extracts / transforms data into key-value pairs.

Reduce: Aggregates and summarizes results.

‚ö†Ô∏è Legacy: Still supported, but Apache Spark is preferred now.

‚ö° 3. Apache Spark (üî• Very Exam-Relevant)
A fast, distributed data processing engine that:
Replaces MapReduce for most tasks.

Uses in-memory computing and a Directed Acyclic Graph (DAG) for optimization.

Works with multiple languages: Python, Scala, Java, R.

‚öôÔ∏è 4. How Spark Works
Component	Function
Driver	Main application coordinator (your script)
Executors	Run computations and store data
Cluster Manager	Allocates resources (e.g. YARN, standalone)

üß± 5. Spark Core Concepts
Term	Meaning
RDD (Resilient Distributed Dataset)	Low-level distributed data structure
DataFrame / Dataset	High-level API like Pandas/SQL table
Spark SQL	Allows SQL-like queries on DataFrames
Zeppelin	Notebook UI to run & visualise Spark code interactively

üß™ 6. Spark Libraries
Library	Purpose
Spark SQL	Run SQL queries on big data (fast, columnar, distributed)
Spark Streaming	Real-time analytics using micro-batches (supports Kinesis, Kafka, etc.)
MLlib	Distributed ML library (LogReg, K-means, LDA, pipelines, etc.)
GraphX	Graph data processing (e.g. social networks)

üìò 7. MLlib Key Algorithms
Classification: Logistic Regression, Naive Bayes

Regression: Linear models

Clustering: K-means

Topic Modelling: LDA

Recommender Systems: ALS

Utils: Pipelines, Feature Transformations, PCA, SVD

üß† Memory Tip:
Spark = Faster MapReduce + Real-time + ML + SQL + Notebooks

üéØ Sample Exam Questions (Try to Guess Before Scrolling!)
Q1. What component of Hadoop allows Spark to allocate cluster resources?
A. HDFS
B. MapReduce
C. Hadoop Common
D. YARN

Q2. Which Spark component provides SQL-like querying on distributed data?
A. RDD
B. Spark SQL
C. Zeppelin
D. GraphX

Q3. What does Spark Streaming do?
A. Stores data in HDFS
B. Allows real-time processing via micro-batches
C. Supports OLTP workloads
D. Manages cluster resources

Q4. Which ML algorithm is not included in Spark MLlib?
A. K-means
B. Logistic Regression
C. Naive Bayes
D. XGBoost

Q5. What is Zeppelin used for in a Spark ecosystem?
A. Running batch ETL jobs
B. Notebook UI for interactive Spark sessions
C. Scheduling Spark Streaming jobs
D. Managing YARN nodes
