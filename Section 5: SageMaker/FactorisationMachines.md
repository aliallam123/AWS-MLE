# ğŸ“˜ SageMaker Built-in Algorithm: Factorization Machines

## âœ… Overview
- **Type**: Supervised (classification & regression)
- **Use Case**: Works best with **sparse data**, especially in **recommendation systems**, click prediction, or any high-dimensional user/item interaction.

## ğŸ“¥ Input Format
- **Only** supports **RecordIOâ€‘Protobuf** (`float32`)
- Not suitable for CSV due to sparsity of large feature spaces

## ğŸ¯ Core Idea
- Models **pairwise interactions** (e.g. userâ€“item) via matrix factorization
- Learns latent feature representations (`num_factors`) + bias + linear terms

## ğŸ”§ Key Hyperparameters
- `feature_dim`: input feature dimension (e.g. # of items + users)
- `num_factors`: latent dimension size (start ~64)
- `predictor_type`: `binary_classifier` or `regressor`
- Optional knobs: `mini_batch_size`, `epochs`, and learning rates (`bias_lr`, `linear_lr`, `factors_lr`)

## ğŸ’» Instance Support
- Preference: **CPU** â€” ideal for sparse data
- **GPU** only helps with dense data (rare in real use cases)
- Supports multi-instance distributed training

## ğŸ“ Exam Tips
- Choose Factorization Machines for **sparse supervised learning** (especially recommendations)
- Always use **RecordIOâ€‘Protobuf**
- Focus on tuning:
  - `num_factors` to balance model complexity vs sparsity
  - Adjust **learning rates** and **batch size**
- Use CPU instances for cost-effective training

