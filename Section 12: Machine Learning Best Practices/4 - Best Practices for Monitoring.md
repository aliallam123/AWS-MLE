# Model Monitoring Best Practices â€“ AWS MLE-A Notes

## Core Monitoring Tools
- ğŸ“Š **SageMaker Model Monitor** â†’ detect drift, anomalies, data quality issues.  
- ğŸ§¾ **SageMaker Clarify** â†’ bias detection, explainability, fairness.  
- ğŸ—‚ï¸ **SageMaker Lineage Tracking** â†’ track data, model, and pipeline history.  
- ğŸ“œ **Model Cards (Clarify)** â†’ governance + documentation of model behavior.  
- ğŸ” **CloudWatch** â†’ system-level metrics/logs.  
- ğŸ”„ **Autoscaling + Elastic Inference** â†’ scale endpoint fleets automatically.  

---

## Best Practices

### Observability & Governance
- ğŸ—ï¸ Synchronize infra/config â†’ **CloudFormation + Model Monitor** (detect environment drift).  
- ğŸ” Secure endpoints â†’ IAM + VPC + GuardDuty/Macie for monitoring anomalous access.  
- ğŸ—‚ï¸ Version control & rollback â†’ **ECR, CodeCommit, SageMaker Pipelines/Projects**.  

### Drift & Explainability
- âš–ï¸ Detect bias/fairness changes â†’ **Clarify**.  
- ğŸ“Š Visualize drift & metrics â†’ **CloudWatch + OpenSearch**.  
- ğŸ” Evaluate feature importance changes â†’ Clarify + Model Monitor.  

### Retraining Strategy
- âš¡ Automate retraining â†’ **Pipelines, Step Functions, Jenkins, SDK**.  
- ğŸ§‘â€âš–ï¸ Add human-in-the-loop â†’ **Amazon A2I** (quality review).  
- ğŸ—‚ï¸ Review incoming data with **Data Wrangler** before retraining.  
- ğŸ›‘ Retrain **only when necessary** â†’ define acceptable accuracy thresholds.  

### Cost & Efficiency
- ğŸ’¸ Track usage & cost â†’ **tagging + AWS Budgets + Cost Explorer**.  
- ğŸ“ˆ Monitor ROI/business value â†’ **QuickSight dashboards**.  
- âš™ï¸ Right-size endpoint fleets â†’ **CloudWatch + Autoscaling + Inference Recommender**.  
- ğŸ—„ï¸ For massive training â†’ **Amazon FSx for Lustre** (higher throughput than S3).  
- â™»ï¸ Define **material efficiency** = (Provisioned resources Ã· Business outcomes).  

---

## Sustainability & Practical Tips
- ğŸ”„ Avoid unnecessary retraining (training = $$$ + energy).  
- âš¡ Use efficient storage/compute (FSx for Lustre, efficient silicon).  
- ğŸŒ± Monitor provisioned vs. used capacity to reduce idle waste.  

---

## ğŸ”‘ Exam Tips
- **Model Monitor** = data drift + anomaly detection.  
- **Clarify** = bias + explainability.  
- **A2I** = human evaluation of results.  
- **Lineage Tracker** = governance + reproducibility.  
- **FSx for Lustre** = preferred storage for very large training jobs.  
- **Budgets/Cost Explorer** = track ML costs.  
- **Retrain only if accuracy/business goals require it** â†’ not on a schedule.  

---
