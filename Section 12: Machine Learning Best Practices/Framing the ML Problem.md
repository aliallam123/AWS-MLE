# Machine Learning Best Practices â€“ AWS MLE-A Notes

## ML Lifecycle (AWS Context)
1. **Data Collection & Prep**  
   - Pre-process, feature engineering.  
   - âœ… Use **SageMaker Feature Store** (online/offline).  
   - âœ… Use **Glue DataBrew** for PII detection, masking, transformation.
  
   - <img width="882" height="389" alt="image" src="https://github.com/user-attachments/assets/b0ac963b-2852-4e83-8727-963d831ca87f" />


2. **Training, Tuning, Evaluation**  
   - Run experiments â†’ **SageMaker Experiments**.  
   - Hyperparameter tuning â†’ **SageMaker Automatic Model Tuning (AMT)**.  
   - AutoML â†’ **SageMaker Autopilot**.  
   - Save versions â†’ **SageMaker Model Registry**.  

3. **Deployment & Inference**  
   - Deploy models via SageMaker endpoints.  
   - Abstract with **API Gateway** â†’ stable API for apps.  
   - Support microservices with **Lambda / Fargate**.  

4. **Monitoring & Feedback Loops**  
   - Model drift/bias â†’ **SageMaker Model Monitor + Clarify**.  
   - Human review â†’ **Amazon A2I** (Augmented AI).  
   - Ops monitoring â†’ **CloudWatch**.  

5. **Governance & Lineage**  
   - Define roles â†’ **SageMaker Role Manager**.  
   - Track pipelines â†’ **SageMaker Lineage + Pipelines**.  

---

## Cost, Sustainability, & Best Practices
- ğŸ’° **Control Costs**  
  - Reuse **pre-trained models** (Bedrock, JumpStart, Marketplace).  
  - Use AutoML to save engineering time.  
  - Compare custom vs pre-trained models â†’ avoid unnecessary training.  

- ğŸŒ± **Sustainability**  
  - Choose greener regions (e.g., US West with hydro).  
  - Optimize compute usage (Spot Instances, right-sized training).  
  - Reduce energy waste by reusing models & fine-tuning instead of training from scratch.  

---

## ğŸ”‘ Exam Tips
- ğŸ“‚ **Model Registry** = versioning + reproducibility.  
- âš™ï¸ **Automatic Model Tuning** = hyperparameter optimization.  
- ğŸ§ª **Experiments** = compare training runs.  
- ğŸ‘€ **Clarify** = bias + explainability checks.  
- ğŸ§‘â€âš–ï¸ **A2I** = human-in-the-loop evaluation.  
- ğŸ”— **Config vs ML** â†’ Config = compliance; **SageMaker Role Manager** = ML roles & permissions.  
- ğŸ’¸ Always evaluate **custom vs pre-trained** for cost & sustainability.  

---
